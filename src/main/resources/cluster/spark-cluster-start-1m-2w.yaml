apiVersion: spark.stackable.de/v1
kind: SparkCluster
metadata:
  name: spark-cluster
spec:
  master:
    selectors:
      - selector: 
         matchLabels:
           kubernetes.io/hostname: "bawa-virtualbox"
    instances: 1
    # no cpu defaults to take all
    cores: "1"
    # no memory defaults to take all
    memory: "1000m"
    command:
      - "spark-3.0.1-bin-hadoop2.7/sbin/start-master.sh"
    env:
#      - name: SPARK_HOME
#        value: "{{packageroot}}/spark-3.0.1-bin-hadoop2.7"
      - name: "SPARK_CONF_DIR"
        value: "{{configroot}}/conf"
#      - name: "SPARK_MASTER_PORT"
#        value: "7077"
        # do not fork processes
      - name: "SPARK_NO_DAEMONIZE"
        value: "true"
  worker:
    selectors:
      - selector: 
         matchLabels:
           kubernetes.io/hostname: "bawa-virtualbox"
    # number of workers
    instances: 2 
    # no cpu defaults to take all
    cores: "1"
    # no memory defaults to take all
    memory: "1000m"
    # end of customization
    command:
      # hostname and port provided from operator: start-slave.sh spark://MASTER_URL:MASTER_PORT
      - "spark-3.0.1-bin-hadoop2.7/sbin/start-slave.sh"
    env:
#      - name: SPARK_HOME
#        value: "{{packageroot}}/spark-3.0.1-bin-hadoop2.7"
      - name: "SPARK_CONF_DIR"
        value: "{{configroot}}/conf"
#      - name: "SPARK_MASTER_PORT"
#        value: "7077"
        # do not fork processes
      - name: "SPARK_NO_DAEMONIZE"
        value: "true"
  image: "spark:3.0.1"
  metrics: false
